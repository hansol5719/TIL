# 웹 크롤링

1. selenium 라이브러리 설치

- selenium의 webdrive는 크롬과 같은 웹 브라우저에서 사람이 할 수 있는 사이트 접속, 버튼 클릭, 글자 입력 등과 같은 일들을 코드를 통해 제어할 수 있다.

```python
! pip install selenium 
```



2. 크롬 드라이버 설치 

- 크롬드라이버는 selenium의 webdrive를 통해 파이썬에서 클모 브루어저 제어할 수 있도록 한다.
- 이미 크롬이 설치되어있더라도 selenium으로 작동하는 크롬드라이버는 별도의 파일이 필요하다.
- 
- 크롬 브라우저 우측 상단 메뉴 [도움말]->[Chrome 정보]통해 사용 중인 버전을 확인한다.

![image-20220112172325676](C:\Users\hansol\AppData\Roaming\Typora\typora-user-images\image-20220112172325676.png)

- [https://chromedriver.chromium.org/downloads] 해당 url로 들어가서 운영체제와 크롬 버전과 일치하는 크롬 드라이버 파일을 다운받는다.

![image-20220112172213040](C:\Users\hansol\AppData\Roaming\Typora\typora-user-images\image-20220112172213040.png)

![image-20220112172250963](C:\Users\hansol\AppData\Roaming\Typora\typora-user-images\image-20220112172250963.png)

3. selenium 라이브러리 불러오기 및 크롬드라이버 실행

```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service

ser = Service('../chromedriver/chromedriver.exe')
driver = webdriver.Chrome(service = ser)
```



4. 웹 페이지 접속

```python
url='https://www.naver.com/'
driver.get(url)
```



5. 웹 페이지(HTML) 다운로드

```python
html = driver.page_source
```



6. HTML 구조

- 시작과 끝이 있다. 
  -  <태그>로 시작해서 </태그>로 끝난다.
  - 태그 부분에 들어가는 태그명은 div, p, span, a, tr, td 등 다양하다.

- 태그는 다른 태그에 속할 수 있다.
  - 태그 시작 부분과 끝 부분 사이에 다른 태그가 들어 있는지로 판단한다.
- 태그의 시작과 끝 사이에 화면에 표시되는 정보가 들어간다
  - <태그> example </태그>의 경우 화면에 example 부분이 표시된다.

- 태그 기호 내 속성을 가질 수 있다.
  - <태그 속성1 = 값1, 속성2=값> example </태그>에서 속성1, 속성2와 같이 여러 속성 정보를 포함할 수 있다.



7. BeautifulSoup 이용한 정보 찾기

```python
html = '''
<html>
    <head>
    </head>
    <body>
        <h1> 우리동네시장</h1>
            <div class = 'sale'>
                <p id='fruits1' class='fruits'>
                    <span class = 'name'> 바나나 </span>
                    <span class = 'price'> 3000원 </span>
                    <span class = 'inventory'> 500개 </span>
                    <span class = 'store'> 가나다상회 </span>
                    <a href = 'http://bit.ly/forPlaywithData' > 홈페이지 </a>
                </p>
            </div>
            <div class = 'prepare'>
                <p id='fruits2' class='fruits'>
                    <span class ='name'> 파인애플 </span>
                </p>
            </div>
    </body>
</html>
'''

# HTML 문자열을 BeautifulSoup으로 해석
from bs4 import BeautifulSoup

# html 문법에 맞게 보기 편하도록 해준다. 크롤링할때 좋음
soup = BeautifulSoup(html, 'html.parser') 
```



8. HTML 정보찾기

```python
# 1. 태그 속성 활용
tags_span = soup.select('span')
tags_p = soup.select('p')

# 2. id로 태그 찾기
soup.select('#fruits1')

# 3. class로 태그 찾기
soup.select('.price') # class 명이 price인 태그 찾기
soup.select('span.price') # 태그명이 span이면서 class 명이 price인 태그 찾기

# 4. 태그구조로 위치찾기
soup.select('#fruits1>span.name') 		   # 부모 태그 정보(#fruits1) 추가
soup.select('div.sale>#fruits1>span.name') # 상위태그(div.sale) 바로 아래 id가 fruits1인 태그 찾고 또 바로 아래 있는 span.name 찾기
soup.select('div.sale>p.fruits>span.name') # 상위태그(div.sale) 바로 아래 class명이 fruits인 p태그 찾고 또 바로 아래 있는 span.name 찾기
soup.select('div.sale span.name') 		   # 상위태그(div.sale) 바로 아래 있는 태그뿐 아니라 몇 단계 아래 태그 중 span.name 찾기
```



9. 정보가져오기

```python
# 태그 그룹에서 하나의 태그만 선택
name = soup.select('span.name')
name_0 = name[0] # 인덱스 번호가 0인 첫 번째 원소
name_1 = name[1] # 인덱스 번호가 1인 첫 번째 원소

name_0.text
name_1.text

# 선택한 태그에서 텍스트, 속성 값 가져오기
tags_a = soup.select('a')
tags = tags_a[0]
content = tags.text # 태그에서 화면에 보이는 텍스트 부분
link = tags['href'] # 태그 내 속성 값
```



